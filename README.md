**Автор**: Богачев Ярослав Павлович, студент 1-го курса ПМИ ИИК Самарского университета имени Королёва
**Дата**: Декабрь 2025

Этот проект является самостоятельной реализацией GPT-архитектуры языковой модели на TF.

## Архитектура:
- **Основа:** Decoder-only Transformer (GPT-style)
- **Параметры:** 4 слоя, 384-dim embeddings, 6 голов внимания
- **Объём:** 13,558,802 обучаемых параметров, 27,117,606 параметров оптимазатора
- **Токенизация:** BPE через SentencePiece
- **Позиционное кодирование:** Синусоидальное (Vaswani et al., 2017)
